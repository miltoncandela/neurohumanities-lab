{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from brainflow import BoardShim, BrainFlowInputParams, LogLevels, BoardIds\n",
    "import time\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "from scipy.signal import welch, butter, lfilter\n",
    "import pickle\n",
    "import pyeeg as pe\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pythonosc import udp_client\n",
    "import random\n",
    "import warnings\n",
    "import serial\n",
    "import math\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import datetime\n",
    "import os\n",
    "from colorama import Fore, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to compute PSD for multiple frequency bands\n",
    "def compute_psd_bands(data, fs):\n",
    "\n",
    "    # Define the frequency ranges for each band\n",
    "    bands = {\n",
    "        'Delta': (0.5, 4),\n",
    "        'Theta': (4, 8),\n",
    "        'Alpha': (8, 12),\n",
    "        'Beta': (12, 30),\n",
    "        'Gamma': (30, 45)\n",
    "    }\n",
    "    \n",
    "    # Compute the PSD for each frequency band\n",
    "    psd_bands = {}\n",
    "    for band, (f_min, f_max) in bands.items():\n",
    "        power = pe.bin_power(data, [f_min, f_max], fs)\n",
    "        psd_bands[band]=np.mean(power)\n",
    "    \n",
    "    return psd_bands\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emocion(arousal, dominance, valence):\n",
    "    valence_1 = valence - 1\n",
    "    arousal_1 = arousal - 1\n",
    "    dominance_1 = dominance - 1\n",
    "\n",
    "    emotions = {\n",
    "        (-1, -1, -1): 'Sadness', \n",
    "        (-1, -1, 0): 'Sadness',\n",
    "        (-1, -1, 1): 'Desire',\n",
    "        (-1, 0, -1): 'Sadness',\n",
    "        (-1, 0, 0): 'Sadness',\n",
    "\n",
    "        (-1, 0, 1): 'Desire',\n",
    "        (-1, 1, -1): 'Sadness',\n",
    "        (-1, 1, 0): 'Sadness',\n",
    "        (-1, 1, 1): 'Desire',\n",
    "        (0, -1, -1): 'Hate',\n",
    "\n",
    "        (0, -1, 0): 'Love',\n",
    "        (0, -1, 1): 'Love',\n",
    "        (0, 0, -1): 'Sadness',\n",
    "        (0, 0, 0): 'Admiration',\n",
    "        (0, 0, 1): 'Desire',\n",
    "\n",
    "        (0, 1, -1): 'Sadness',\n",
    "        (0, 1, 0): 'Desire',\n",
    "        (0, 1, 1): 'Desire',\n",
    "        (1, -1, -1): 'Hate',\n",
    "        (1, -1, 0): 'Admiration',\n",
    "\n",
    "        (1, -1, 1): 'Love',\n",
    "        (1, 0, -1): 'Hate',\n",
    "        (1, 0, 0): 'Admiration',\n",
    "        (1, 0, 1): 'Joy',\n",
    "        (1, 1, -1): 'Admiration',\n",
    "    \n",
    "        (1, 1, 0): 'Admiration',\n",
    "        (1, 1, 1): 'Joy'\n",
    "    }\n",
    "\n",
    "    return emotions.get((arousal_1, dominance_1, valence_1), 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_emotion(emo):\n",
    "    map_emotions = {\"Sadness\": \"Sadness\",\n",
    "                    \"Rejected\": None,\n",
    "                    \"Pessimistic\": None,\n",
    "                    \"Hate\": \"Hate\",\n",
    "                    \"Distressed\": None, \n",
    "                    \"Anxious\": None,\n",
    "                    \"Calm\": None,\n",
    "                    \"Neutral\": None,\n",
    "                    \"Admiration\": \"Admiration\",\n",
    "                    \"Relief\": None,\n",
    "                    \"Relaxed\": None,\n",
    "                    \"Overconfident\": None,\n",
    "                    \"Satisfied\": None,\n",
    "                    \"Desire\": \"Desire\",\n",
    "                    \"Love\": \"Love\",\n",
    "                    \"Joy\": \"Joy\",\n",
    "                    \"Generosity\": None \n",
    "                    }\n",
    "    #emo = map_emotions[emo]\n",
    "    \n",
    "    if emo == \"Love\":\n",
    "        return 1\n",
    "    elif emo == \"Hate\":\n",
    "        return 2\n",
    "    elif emo == \"Desire\":\n",
    "        return 3\n",
    "    elif emo == \"Admiration\":\n",
    "        return 4\n",
    "    elif emo == \"Joy\":\n",
    "        return 5\n",
    "    elif emo == \"Sadness\":\n",
    "        return 6\n",
    "    else: \n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_Pkl = pickle.load(open('Val_RF_10s.pkl', 'rb'))\n",
    "Aro_Pkl = pickle.load(open('Aro_RF_10s.pkl', 'rb'))\n",
    "Dom_Pkl = pickle.load(open('Dom_RF_10s.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteraciones = 0\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = \"10.12.181.191\"  # IP address of the receiving device\n",
    "port1 = 9000 # Port number of the receiving device\n",
    "port2 = 9001\n",
    "\n",
    "port3 = 7000\n",
    "port4 = 7001\n",
    "\n",
    "client1 = udp_client.SimpleUDPClient(ip, port1)\n",
    "client2 = udp_client.SimpleUDPClient(ip, port2)\n",
    "\n",
    "client3 = udp_client.SimpleUDPClient(ip, port3)\n",
    "client4 = udp_client.SimpleUDPClient(ip, port4)\n",
    "\n",
    "address = \"/engagement\"  # OSC address to send the message to\n",
    "address2 = \"/real-emotion\"  # OSC address to send the message to\n",
    "address3 = \"/emotion-ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the duration to stream data (5 seconds in this example)\n",
    "duration = 10 # queremos 10 segundos\n",
    "# Set the sampling rate and channel(s) you want to stream\n",
    "\n",
    "## SEPTEMBER 28 UPDATE ##\n",
    "sampling_rate = 250 # used to be 128, queremos 250 Hz\n",
    "\n",
    "#channels = (0, 1, 2, 3, 4, 5, 6, 7)  # Streaming data from channels 0 to 7\n",
    "channels = list(range(9))   # Streaming data from channels 0 to 7\\n\",\n",
    "\n",
    "\n",
    "# Initialize the board\n",
    "# Create BrainFlowInputParams object and set the parameters\n",
    "\"\"\"params = BrainFlowInputParams()\n",
    "params.serial_port = 'COM4'  # Replace with the actual serial port of OpenBCI Cyton board\n",
    "board = BoardShim(0, params)\n",
    "board.prepare_session()\n",
    "timestamp_channel = board.get_timestamp_channel(BoardIds.CYTON_BOARD.value) \n",
    "acc_channel = board.get_accel_channels(BoardIds.CYTON_BOARD.value)\"\"\"\n",
    "\n",
    "## LINES FOR SYNTHETIC ##\n",
    "params = BrainFlowInputParams()\n",
    "board = BoardShim(BoardIds.SYNTHETIC_BOARD.value, params)\n",
    "board.prepare_session()\n",
    "timestamp_channel = board.get_timestamp_channel(BoardIds.SYNTHETIC_BOARD.value)\n",
    "acc_channel = board.get_accel_channels(BoardIds.SYNTHETIC_BOARD.value)\n",
    "\n",
    "\n",
    "\"\"\"arduino = serial.Serial(port='COM9', baudrate=115200, timeout=.1)\n",
    "def write_read(x,y,z):\n",
    "    arduino.write(bytes(str(x), 'utf-8'))\n",
    "    time.sleep(0.05)\n",
    "    arduino.write(bytes(str(y), 'utf-8'))\n",
    "    time.sleep(0.05)\n",
    "    arduino.write(bytes(str(z), 'utf-8'))\n",
    "    time.sleep(0.05)\"\"\"\n",
    "\n",
    "count = 0\n",
    "repetitions = 0\n",
    "\n",
    "escalado_11 = lambda x: (x - 0.5)*2  ## CAMBIAR 0.5 POR VALOR NEUTRO DE ENGAGEMENT??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ID, repetition_num = input('Please enter the subject ID and the number of repetition: ').split(' ')\n",
    "subject_ID = '0' + subject_ID if int(subject_ID) < 10 else subject_ID\n",
    "repetition_num = '0' + repetition_num if int(repetition_num) < 10 else repetition_num\n",
    "folder = 'S{}R{}_{}'.format(subject_ID, repetition_num, datetime.datetime.now().strftime(\"%d%m%Y_%H%M\"))\n",
    "os.mkdir(folder)\n",
    "\n",
    "df_eeg = pd.DataFrame()\n",
    "df_time = pd.DataFrame()\n",
    "df_emotions = pd.DataFrame(data = [], columns=['Timestamp', 'Engagement', 'Emotion', 'Valence', 'Arousal', 'Dominance'])\n",
    "df_acc = pd.DataFrame() # acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitializing functions...\u001b[0m\n",
      "2 1 1\n",
      "Desire\n",
      "0.9064609171157876\n",
      "2 1 1\n",
      "Desire\n",
      "0.9871216318406482\n",
      "2 1 1\n",
      "Desire\n",
      "0.961405197282466\n",
      "\u001b[34mTest interrupted. Storing data...\u001b[0m\n",
      "\u001b[32mData stored.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(Fore.RED + 'Initializing functions...' + Style.RESET_ALL)\n",
    "\n",
    "try:   \n",
    "    while iteraciones < 2000:\n",
    "\n",
    "        # Create empty lists to store the streamed data for each channel\n",
    "        channel_data = [[] for _ in channels]\n",
    "        channel_data_acc = [[] for _ in acc_channel] # acceleration\n",
    "\n",
    "        # Start the streaming\n",
    "        board.start_stream()\n",
    "\n",
    "        # Get the start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Loop until the specified duration is reached\n",
    "        while time.time() - start_time < duration:\n",
    "            # Fetch the latest available samples\n",
    "            samples = board.get_current_board_data(sampling_rate)\n",
    "\n",
    "            # Append the samples to the corresponding channel's data list\n",
    "            for i, channel in enumerate(channels):\n",
    "                channel_data[i].extend(samples[channel])\n",
    "\n",
    "            np_time = np.array(samples[timestamp_channel])\n",
    "            np_time = np_time - 21600 # time zone converter to GMT-6\n",
    "            np_df = pd.DataFrame(np_time)\n",
    "            df_time = df_time.append(np_df)\n",
    "            \n",
    "            \n",
    "            ## ACCELERATION ##\n",
    "            \n",
    "            for i, channel in enumerate(acc_channel):\n",
    "                channel_data_acc[i].extend(samples[channel])\n",
    "                                \n",
    "\n",
    "            # Sleep for a small interval to avoid high CPU usage\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Stop the streaming\n",
    "        board.stop_stream()\n",
    "        \n",
    "        # acceleration dataframe\n",
    "        data_dict_acc = {f'Channel_{channel}': channel_data_acc[i] for i, channel in enumerate(acc_channel)}\n",
    "        df_acc_prueba = pd.DataFrame(data_dict_acc)\n",
    "        df_acc = df_acc.append(df_acc_prueba)\n",
    "\n",
    "\n",
    "        # Create a dictionary with channel names as keys and data as values\n",
    "        data_dict = {f'Channel_{channel}': channel_data[i] for i, channel in enumerate(channels)}\n",
    "\n",
    "        # Create a DataFrame from the data dictionary\n",
    "        df = pd.DataFrame(data_dict)\n",
    "\n",
    "        row_all_zeros = (df == 0).all(axis=1)\n",
    "        df2 = df[~row_all_zeros]\n",
    "        df3 = df2.drop(df.columns[0], axis=1)\n",
    "        df4 = df3[['Channel_1', 'Channel_2', 'Channel_3', 'Channel_4', 'Channel_5', 'Channel_6', 'Channel_7', 'Channel_8']].copy()\n",
    "        \n",
    "        \n",
    "        # Append data to global dataframe\n",
    "        df_eeg = df_eeg.append(df4)\n",
    "                \n",
    "        lowcut = 0.4  # Lower cutoff frequency in Hz\n",
    "        highcut = 45  # Upper cutoff frequency in Hz\n",
    "        fs = 128  # Sampling rate in Hz\n",
    "\n",
    "        ratio = 128/250\n",
    "        df5 = df4.iloc[::int(1/ratio)].interpolate()\n",
    "\n",
    "        # Apply the bandpass filter to each column\n",
    "        filtered_df = df5.apply(lambda col: butter_bandpass_filter(col, lowcut, highcut, fs))\n",
    "\n",
    "        average_reference = filtered_df.mean(axis=1)\n",
    "        df_average_reference = filtered_df.sub(average_reference, axis=0)\n",
    "\n",
    "        # Create an empty DataFrame to store the PSD results\n",
    "        psd_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate over each column in your DataFrame\n",
    "        for column in df_average_reference.columns:\n",
    "            # Compute the PSD for the column data and frequency bands\n",
    "            psd_bands = compute_psd_bands(df_average_reference[column].values, fs=128)\n",
    "        \n",
    "            # Add the PSD values to the DataFrame\n",
    "            psd_df = psd_df.append(psd_bands, ignore_index=True)\n",
    "\n",
    "        df_t = psd_df.transpose()\n",
    "        df_t.columns = ['Fp1', 'Fp2', 'C3', 'C4', 'P7', 'P8', 'O1', 'O2']\n",
    "\n",
    "        df_t = df_t.reset_index()\n",
    "\n",
    "        # Use the melt function to reshape the DataFrame\n",
    "        melted_df = pd.melt(df_t, id_vars='index', var_name='channel', value_name='value')\n",
    "\n",
    "        # Convert channel numbers to strings\n",
    "        melted_df['channel'] = melted_df['channel'].astype(str)\n",
    "\n",
    "        # Create a new 'channel_band' column by combining 'channel' and 'index' columns\n",
    "        melted_df['channel_band'] = melted_df['channel'] + '_' + melted_df['index']\n",
    "\n",
    "        # Pivot the DataFrame to get the desired format\n",
    "        new_df = melted_df.pivot(index='index', columns='channel_band', values='value')\n",
    "\n",
    "        series = new_df.stack()\n",
    "\n",
    "        # Convert the Series back to a DataFrame with a single row\n",
    "        filter_df = pd.DataFrame(series)\n",
    "\n",
    "        valo =filter_df[0]\n",
    "        valores = valo.reset_index(drop=True)\n",
    "        df_modelo = pd.DataFrame(valores).transpose()\n",
    "\n",
    "        df_modelo.columns = ['Fp1_Delta', 'Fp1_Theta', 'Fp1_Alpha','Fp1_Beta','Fp1_Gamma',\n",
    "                             'Fp2_Delta', 'Fp2_Theta', 'Fp2_Alpha','Fp2_Beta','Fp2_Gamma',\n",
    "                             'C3_Delta', 'C3_Theta', 'C3_Alpha','C3_Beta','C3_Gamma',\n",
    "                             'C4_Delta', 'C4_Theta', 'C4_Alpha','C4_Beta','C4_Gamma',\n",
    "                             'P7_Delta', 'P7_Theta', 'P7_Alpha','P7_Beta','P7_Gamma',\n",
    "                             'P8_Delta', 'P8_Theta', 'P8_Alpha','P8_Beta','P8_Gamma',\n",
    "                             'O1_Delta', 'O1_Theta', 'O1_Alpha','O1_Beta','O1_Gamma',\n",
    "                             'O2_Delta', 'O2_Theta', 'O2_Alpha','O2_Beta','O2_Gamma',]\n",
    "        \n",
    "        df_pred = df_modelo.reset_index(drop=True)\n",
    "\n",
    "        CANALES = ['Fp1', 'Fp2', 'C3', 'C4', 'P7', 'P8', 'O1', 'O2']\n",
    "\n",
    "        for channel in CANALES:\n",
    "            df_pred[f'{channel}_Engagement'] = df_pred[f'{channel}_Beta'] / (df_pred[f'{channel}_Theta'] + df_pred[f'{channel}_Alpha'])\n",
    "\n",
    "        for channel in CANALES:\n",
    "            df_pred[f'{channel}_Fatigue'] = df_pred[f'{channel}_Alpha'] / df_pred[f'{channel}_Theta']\n",
    "\n",
    "        for channel in CANALES:\n",
    "            df_pred[f'{channel}_Excitement'] = df_pred[f'{channel}_Beta'] / df_pred[f'{channel}_Alpha']\n",
    "\n",
    "        for channel in CANALES:\n",
    "            df_pred[f'{channel}_Relaxation'] = df_pred[f'{channel}_Theta'] / df_pred[f'{channel}_Delta']\n",
    "\n",
    "\n",
    "\n",
    "        iteraciones + 1\n",
    "\n",
    "\n",
    "        valen = Val_Pkl.predict(df_pred)\n",
    "        arous = Aro_Pkl.predict(df_pred)\n",
    "        domin = Dom_Pkl.predict(df_pred)\n",
    "                 \n",
    "        engag_fp1 = mean(df_pred[\"Fp1_Engagement\"])\n",
    "        engag_fp2 = mean(df_pred[\"Fp2_Engagement\"])\n",
    "        engag_c3 = mean(df_pred[\"C3_Engagement\"])\n",
    "        engag_c4 = mean(df_pred[\"C4_Engagement\"])\n",
    "        engag_p7 = mean(df_pred[\"P7_Engagement\"])\n",
    "        engag_p8 = mean(df_pred[\"P8_Engagement\"])\n",
    "        engag_o1 = mean(df_pred[\"O1_Engagement\"])\n",
    "        engag_o2 = mean(df_pred[\"O2_Engagement\"])\n",
    "\n",
    "\n",
    "        ## LINEAS ACTUALES - SE CAMBIARON EL 25 DE AGOSTO DE 2023 ##\n",
    "        ##engagement = ((engag_fp1+engag_fp2+engag_c3+engag_c4+engag_p7+engag_p8+engag_o1+engag_o2)/8)\n",
    "        engagement = ((engag_fp1+engag_fp2)/2)\n",
    "        engag = escalado_11(engagement)\n",
    "        \n",
    "        #engag = math.log((engag_fp1+engag_fp2)/2) #se agregó el logaritmo\n",
    "        #engag = engag/2                           #se divide sobre 2 (rangos aprox de -2 a 2), con los IF, se limita a -1 y 1\n",
    "        if engag <= -1:\n",
    "            engag = -1\n",
    "        if engag >=1:\n",
    "            engag = 1\n",
    "\n",
    "        ## LINEAS ANTERIORES -  CAMBIARON EL 25 DE AGOSTO DE 2023 ##\n",
    "        #engag = ((engag_fp1+engag_fp2)/2*10) #se agregó una multiplicación \n",
    "        #engag = escalado_11(engag)\n",
    "        \n",
    "        vale = mean(valen)\n",
    "        arou = mean(arous)\n",
    "        domi = mean(domin)\n",
    "        print(vale, arou, domi) #descomentar\n",
    "        emociones = emocion(arou, domi, vale)\n",
    "        #write_read(vale, arou, domi)\n",
    "        values = [vale, arou, domin]\n",
    "        client1.send_message(address, engag)\n",
    "        client2.send_message(address, engag)\n",
    "\n",
    "        realemotion = real_emotion(emociones)\n",
    "\n",
    "        client3.send_message(address2, emociones)\n",
    "        client3.send_message(address3, realemotion)\n",
    "\n",
    "        client4.send_message(address2, emociones)\n",
    "        client4.send_message(address3, realemotion)\n",
    "\n",
    "        df_emotions.loc[len(df_emotions)] = [time.time()- 21600, engag, emociones, vale, arou, domi]      \n",
    "\n",
    "        print(emociones) #descomentar\n",
    "        print(engag) #descomentar\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "        \n",
    "    print(Fore.BLUE + 'Test interrupted. Storing data...' + Style.RESET_ALL)        \n",
    "\n",
    "    df_eeg = df_eeg.reset_index(drop=True)\n",
    "    df_time = df_time.reset_index(drop=True)  \n",
    "    df_time.columns = ['Timestamp']\n",
    "    df_emotions = df_emotions.reset_index(drop=True)  \n",
    "    \n",
    "    \n",
    "    df_acc = df_acc.reset_index(drop=True) \n",
    "    df_acc.columns = ['Acc_1', 'Acc_2', 'Acc_3']     \n",
    "       \n",
    "    # acceleration\n",
    "    #print(df_acc.shape)\n",
    "    #print(df_eeg.shape)  \n",
    "\n",
    "    \n",
    "    df_complete = pd.concat([df_time, df_eeg, df_acc], axis=1)\n",
    "    df_complete = df_complete.reset_index(drop=True)  \n",
    "      \n",
    "    #df_eeg.to_csv('{}/EEG.csv'.format(folder), mode='a')\n",
    "    #df_time.to_csv('{}/TimeStamps.csv'.format(folder), mode='a') \n",
    "    \n",
    "    df_complete.to_csv('{}/Complete.csv'.format(folder), mode='a')\n",
    "    df_emotions.to_csv('{}/Emotions.csv'.format(folder), mode='a') \n",
    "    #df_acc.to_csv('{}/Acceleration.csv'.format(folder), mode='a') # acceleration\n",
    "\n",
    "    \n",
    "    board.stop_stream()\n",
    "    board.release_session()\n",
    "    print(Fore.GREEN + 'Data stored.' + Style.RESET_ALL)        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALAS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
