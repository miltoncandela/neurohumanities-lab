{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la biblioteca NumPy para operaciones numéricas y matrices multidimensionales\n",
    "import numpy as np \n",
    "\n",
    "# Importamos la biblioteca Pandas para análisis de datos tabulares\n",
    "import pandas as pd \n",
    "\n",
    "# Importamos el módulo math para funciones matemáticas básicas\n",
    "import math\n",
    "\n",
    "# Importamos el módulo pyeeg para cálculos de características de señales EEG\n",
    "import pyeeg as pe\n",
    "\n",
    "# Importamos el módulo pickle para serialización de objetos Python\n",
    "import pickle as pickle \n",
    "\n",
    "# Importamos el módulo os para interacción con el sistema operativo\n",
    "import os \n",
    "\n",
    "# Importamos el módulo time para trabajar con medidas de tiempo\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para la función np.load para cargar archivos. \n",
    "# Los valores por defecto establecidos incluyen el uso de codificación ASCII.\n",
    "np.load.__defaults__=(None, True, True, 'ASCII')\n",
    "\n",
    "# Definición de los canales EEG que se desean utilizar (8 canales de openbci).\n",
    "channel = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32]\n",
    "\n",
    "# Frecuencias de las bandas para calcular el espectro de potencia (PSD) de la señal EEG.\n",
    "band = [.5,4,8,12,30,45]  # Definición de 5 bandas.\n",
    "\n",
    "# Tamaño de ventana para promediar la potencia en bandas durante 5 segundos (downsampleado a 128 Hz).\n",
    "window_size = 128 * 5  # Ventana de 5 segundos a una frecuencia de muestreo de 128 Hz.\n",
    "\n",
    "# Paso para actualizar el tiempo cada ciertos pasos.\n",
    "step_size = 16  # Actualizar cada 0.125 segundos.\n",
    "\n",
    "# Frecuencia de muestreo de la señal EEG.\n",
    "sample_rate = 128  # Frecuencia de muestreo de 128 Hz.\n",
    "\n",
    "# Lista de sujetos para cargar los datos.\n",
    "subjectList = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función para procesar datos EEG\n",
    "def FFT_Processing(sub, channel, band, window_size, step_size, sample_rate):\n",
    "    # Lista para almacenar metadatos\n",
    "    meta = []\n",
    "\n",
    "    # Abrir los datos usando pickle para descomprimir\n",
    "    with open('datos\\s' + sub + '.dat', 'rb') as file:\n",
    "        subject = pickle.load(file, encoding='latin1')  # Resuelve el problema de datos de Python 2 utilizando la codificación latin1\n",
    "\n",
    "        for i in range(0, 40):\n",
    "            # Para las 40 pruebas realizadas\n",
    "            data = subject[\"data\"][i] \n",
    "            labels = subject[\"labels\"][i]\n",
    "            start = 0\n",
    "\n",
    "            while start + window_size < data.shape[1]:\n",
    "                meta_array = []\n",
    "                meta_data = []  # Vector de metadatos para el análisis\n",
    "                for j in channel:\n",
    "                    X = data[j][start : start + window_size]  # Dividir los datos crudos en ventanas de 2 segundos, con un intervalo de 0.125 segundos\n",
    "                    Y = pe.bin_power(X, band, sample_rate)  # FFT en 5 segundos del canal j, en secuencia de theta, alpha, beta baja, beta alta, gamma\n",
    "                    meta_data = meta_data + list(Y[0])\n",
    "\n",
    "                meta_array.append(np.array(meta_data))\n",
    "                meta_array.append(labels)\n",
    "\n",
    "                meta.append(np.array(meta_array))    \n",
    "                start = start + step_size\n",
    "\n",
    "        meta = np.array(meta)\n",
    "        np.save('out\\s' + sub, meta, allow_pickle=True, fix_imports=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-1f4853850be8>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  meta.append(np.array(meta_array))\n"
     ]
    }
   ],
   "source": [
    "for subjects in subjectList:\n",
    "    FFT_Processing (subjects, channel, band, window_size, step_size, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: (445440, 160) (445440, 4)\n",
      "Testing dataset: (74240, 160) (74240, 4)\n",
      "Validation dataset: (74240, 160) (74240, 4)\n"
     ]
    }
   ],
   "source": [
    "# Listas para almacenar datos y etiquetas de los diferentes conjuntos\n",
    "data_training = []\n",
    "label_training = []\n",
    "data_testing = []\n",
    "label_testing = []\n",
    "data_validation = []\n",
    "label_validation = []\n",
    "\n",
    "# Iteramos sobre la lista de sujetos\n",
    "for subject in subjectList:\n",
    "    # Cargamos los datos procesados para el sujeto actual\n",
    "    with open(os.path.join('out', f's{subject}.npy'), 'rb') as file:\n",
    "        sub = np.load(file)\n",
    "        # Iteramos sobre los datos procesados del sujeto\n",
    "        for i in range(sub.shape[0]):\n",
    "            if i % 8 == 0:\n",
    "                data_testing.append(sub[i][0])\n",
    "                label_testing.append(sub[i][1])\n",
    "            elif i % 8 == 1:\n",
    "                data_validation.append(sub[i][0])\n",
    "                label_validation.append(sub[i][1])\n",
    "            else:\n",
    "                data_training.append(sub[i][0])\n",
    "                label_training.append(sub[i][1])\n",
    "\n",
    "# Guardamos los conjuntos de datos y etiquetas en archivos\n",
    "np.save(os.path.join('out', 'data_training.npy'), np.array(data_training), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'label_training.npy'), np.array(label_training), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'data_testing.npy'), np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'label_testing.npy'), np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'data_validation.npy'), np.array(data_validation), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'label_validation.npy'), np.array(label_validation), allow_pickle=True, fix_imports=True)\n",
    "\n",
    "# Imprimimos las dimensiones de los conjuntos de datos y etiquetas para cada conjunto\n",
    "print(\"Training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
    "print(\"Testing dataset:\", np.array(data_testing).shape, np.array(label_testing).shape)\n",
    "print(\"Validation dataset:\", np.array(data_validation).shape, np.array(label_validation).shape)\n",
    "\n",
    "# Restauramos los valores por defecto para la función np.load\n",
    "np.load.__defaults__=(None, False, True, 'ASCII')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALAS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
